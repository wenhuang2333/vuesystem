import asyncio
from pysentimiento import create_analyzer
from googletrans import Translator
from langdetect import detect, LangDetectException


async def analyze_emotion_chinese_output(text_list):
    """
    ä½¿ç”¨pysentimientoåº“åˆ†æä¸€ç³»åˆ—æ–‡æœ¬çš„æƒ…ç»ªæ¦‚ç‡ã€‚
    å¦‚æœæ£€æµ‹åˆ°æ–‡æœ¬ä¸ºä¸­æ–‡ï¼Œåˆ™å…ˆç¿»è¯‘æˆè‹±æ–‡å†è¿›è¡Œåˆ†æã€‚
    """
    # ä¸­è‹±æ–‡æƒ…ç»ªæ ‡ç­¾çš„æ˜ å°„å­—å…¸
    emotion_translation_map1 = {
        'joy': 'å–œæ‚¦ğŸ˜„',
        'sadness': 'æ‚²ä¼¤ğŸ˜¢',
        'anger': 'æ„¤æ€’ğŸ˜ ',
        'fear': 'ææƒ§ğŸ˜¨',
        'disgust': 'åŒæ¶ğŸ¤¢',
        'surprise': 'æƒŠå–œğŸ˜®',
        'others': 'å…¶ä»–ğŸ˜'
    }
    emotion_translation_map = {
        'joy': 'joy',
        'sadness': 'sad',
        'anger': 'anger',
        'fear': 'fear',
        'disgust': 'disgust',
        'surprise': 'surprise',
        'others': 'others'
    }
    results = []  # ç”¨äºå­˜å‚¨æ‰€æœ‰æ–‡æœ¬çš„åˆ†æç»“æœ

    # åˆå§‹åŒ–ç¿»è¯‘å™¨
    try:
        translator = Translator()
    except Exception as e:
        print(f"åˆå§‹åŒ–ç¿»è¯‘å™¨å¤±è´¥: {e}")
        print("è¯·æ£€æŸ¥æ‚¨çš„ç½‘ç»œè¿æ¥æˆ–å°è¯•æ›´æ–°åº“: pip install googletrans==4.0.0-rc1")
        return

    # åˆ›å»ºæƒ…ç»ªåˆ†æå™¨(ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶ä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹)
    try:
        print("æ­£åœ¨åŠ è½½æƒ…ç»ªåˆ†ææ¨¡å‹...")
        emotion_analyzer = create_analyzer(task="emotion", lang="en")
        print("æ¨¡å‹åŠ è½½å®Œæ¯•ï¼")
    except Exception as e:
        print(f"åˆå§‹åŒ–æ¨¡å‹å¤±è´¥: {e}")
        print("è¯·æ£€æŸ¥æ‚¨çš„ç½‘ç»œè¿æ¥æˆ–å°è¯•æ›´æ–°åº“: pip install -U pysentimiento transformers")
        return

    print("\n--- å¤šæƒ…ç»ªæ¦‚ç‡åˆ†æ  ---")

    for i, original_text in enumerate(text_list):
        text_to_analyze = original_text
        translation_info = ""
        re = {}  # ä¸ºæ¯ä¸ªæ–‡æœ¬åˆ›å»ºä¸€ä¸ªæ–°çš„å­—å…¸

        try:
            lang = detect(original_text)
            if lang.startswith('zh'):
                translated = await translator.translate(original_text, src='auto', dest='en')
                text_to_analyze = translated.text
                translation_info = f" (ä¸­æ–‡åŸæ–‡å·²ç¿»è¯‘ä¸º: '{text_to_analyze}')"
        except LangDetectException:
            print(f"\nè­¦å‘Š: æ–‡æœ¬ '{original_text}' è¯­è¨€æ£€æµ‹å¤±è´¥ï¼Œå°†æŒ‰åŸæ–‡å¤„ç†ã€‚")
        except Exception as e:
            print(f"\né”™è¯¯: æ–‡æœ¬ '{original_text}' ç¿»è¯‘å¤±è´¥: {e}ï¼Œå°†æŒ‰åŸæ–‡å¤„ç†ã€‚")

        analysis_result = emotion_analyzer.predict(text_to_analyze)

        main_emotion_en = analysis_result.output
        main_emotion_zh = emotion_translation_map.get(main_emotion_en, main_emotion_en)

        probabilities = analysis_result.probas
        probabilities_zh = {
            emotion_translation_map.get(en_label, en_label): prob
            for en_label, prob in probabilities.items()
        }

        print(f"\næ–‡æœ¬ {i + 1}: '{original_text}'{translation_info}")
        print(f"ä¸»è¦æƒ…ç»ª: {main_emotion_zh}")
        print("--- å„æƒ…ç»ªæ¦‚ç‡åˆ†å¸ƒ ---")

        for emotion_zh, prob in probabilities_zh.items():
            print(f"- {emotion_zh:<5}: {prob:.2%}")
            re[emotion_zh] = f"{prob:.2%}"

        re['main'] = main_emotion_zh
        results.append(re)  # å°†æ¯ä¸ªæ–‡æœ¬çš„åˆ†æç»“æœå­˜å‚¨åˆ°åˆ—è¡¨ä¸­

    return results  # è¿”å›æ‰€æœ‰æ–‡æœ¬çš„åˆ†æç»“æœ


def calculate_average_probabilities(results):
    """
    è®¡ç®—æ‰€æœ‰å­—å…¸ä¸­ç›¸å…³å±æ€§çš„å¹³å‡å€¼
    """
    if not results:
        return {}

    # åˆå§‹åŒ–ä¸€ä¸ªå­—å…¸æ¥å­˜å‚¨æ€»å’Œ
    total_probabilities = {key: 0.0 for key in results[0].keys() if key != 'main'}
    count = len(results)

    # éå†æ‰€æœ‰ç»“æœï¼Œç´¯åŠ æ¯ä¸ªå±æ€§çš„å€¼
    for result in results:
        for key, value in result.items():
            if key != 'main':
                # å»æ‰ç™¾åˆ†å·å¹¶è½¬æ¢ä¸ºæµ®ç‚¹æ•°
                total_probabilities[key] += float(value.strip('%'))

    # è®¡ç®—å¹³å‡å€¼
    average_probabilities = {key: f"{value / count:.2f}%" for key, value in total_probabilities.items()}
    return average_probabilities

def text_test_before(sample_texts):
    results = asyncio.run(analyze_emotion_chinese_output(sample_texts))
    average_probabilities = calculate_average_probabilities(results)
    print("å¹³å‡æ•°",average_probabilities)
    return {key: float(value.strip('%')) for key, value in average_probabilities.items()}
def text_text(sample):
    re=[]
    sample_dic=text_test_before(sample)
    re.append(sample_dic['joy'])
    re.append(sample_dic['sad'])
    re.append(sample_dic['anger'])
    re.append(sample_dic['surprise'])
    re.append(sample_dic['disgust'])
    re.append(sample_dic['fear'])
    re.append(sample_dic['others'])
    return re


if __name__ == "__main__":
    sample_texts = [
        "I am so happy and excited about my promotion!",
        "è¿™éƒ¨ç”µå½±çš„ç»“å±€å¤ªæ‚²ä¼¤äº†ï¼Œæˆ‘å¿ä¸ä½å“­äº†ã€‚",
        "é‚£ä¸ªå®¢æœå¤ªæ°”äººäº†ï¼Œä¸šåŠ¡å®Œå…¨ä¸ç†Ÿç»ƒï¼",
        "That customer service agent made me so angry with their incompetence!",
        "èµ°åœ¨æ¼†é»‘çš„å°å··é‡Œï¼Œæˆ‘æ„Ÿåˆ°éå¸¸å®³æ€•ã€‚",
        "Wow, I wasn't expecting that ending! What a surprise!",
        "è¿™åªæ˜¯ä¸€ä¸ªå…³äºä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·çš„æ™®é€šé™ˆè¿°ã€‚",
        "This is just a regular statement about the weather."
    ]
    second_texts = [
        "I am so happy and excited about my promotion!",
        "I am excited!",
        "what a good day!I love it!",
        "Wow!I like the life now I have!"
    ]
    print(text_text(second_texts))