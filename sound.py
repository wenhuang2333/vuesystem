"""
æ­¤ç¨‹åºç”¨äºæµ‹è¯•é¢„è®­ç»ƒçš„SVMè¯­éŸ³æƒ…æ„Ÿè¯†åˆ«æ¨¡å‹ã€‚
å®ƒä¼šåŠ è½½ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼Œæå–å…¶ç‰¹å¾ï¼Œç„¶åä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæƒ…æ„Ÿé¢„æµ‹ã€‚
"""

# é€šç”¨æ¨¡å—å¯¼å…¥
import os
import sys
import pickle
import numpy as np
import scipy
import librosa
from pydub import AudioSegment

# æŠ¥è­¦æ¨¡å—å¯¼å…¥
import warnings
warnings.filterwarnings('ignore')

# æœºå™¨å­¦ä¹ æ¨¡å—å¯¼å…¥
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectKBest
from sklearn.impute import SimpleImputer

# éŸ³é¢‘é¢„å¤„ç†æ¨¡å—å¯¼å…¥
from AudioLibrary.AudioSignal import AudioSignal
from AudioLibrary.AudioFeatures import AudioFeatures

# æ¨¡å‹å’Œæ•°æ®çš„æ–‡ä»¶å¤¹è·¯å¾„
MODEL_FOLDER = './must2/Model/'
DATA_FOLDER = './must2/Datas/'

# å¾…æµ‹è¯•çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„ (è¯·å°†æ‚¨çš„æµ‹è¯•éŸ³é¢‘æ”¾åœ¨æ­¤è·¯å¾„ä¸‹)
TEST_AUDIO_PATH = os.path.join(DATA_FOLDER, 'TestAudio', 'test_audio.wav')
path="./must2/Datas/TestAudio/æ‚²ä¼¤.wav"
# æƒ…æ„Ÿæ ‡ç­¾æ˜ å°„
# EMOTION_MAP = {'NEU': 'å¹³é™ğŸ˜', 'HAP': 'é«˜å…´ğŸ˜„', 'SAD': 'æ‚²ä¼¤ğŸ˜¢', 'ANG': 'æ„¤æ€’ğŸ˜ ', 'FEA': 'ææƒ§ğŸ˜¨', 'DIS': 'åŒæ¶ğŸ¤¢', 'SUR': 'æƒŠè®¶ğŸ˜®'}
EMOTION_MAP = {'NEU': 'å¹³é™', 'HAP': 'é«˜å…´', 'SAD': 'æ‚²ä¼¤', 'ANG': 'æ„¤æ€’', 'FEA': 'ææƒ§', 'DIS': 'åŒæ¶',
               'SUR': 'æƒŠè®¶'}

# å®šä¹‰ç‰¹å¾æå–å‡½æ•°(ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´)
def global_feature_statistics(y, win_size=0.025, win_step=0.01,
                              stats=['mean', 'std', 'med', 'kurt', 'skew', 'q1', 'q99', 'min', 'max', 'range'],
                              features_list=['zcr', 'energy', 'energy_entropy', 'spectral_centroid', 'spectral_spread',
                                             'spectral_entropy', 'spectral_flux', 'sprectral_rolloff', 'mfcc']):
    """ä»éŸ³é¢‘ä¿¡å·ä¸­æå–å…¨å±€ç‰¹å¾ç»Ÿè®¡æ•°æ®"""
    # è®­ç»ƒæ—¶ä½¿ç”¨äº†12ä¸ªMFCCç³»æ•°
    nb_mfcc = 12
    # ä½¿ç”¨AudioFeaturesç±»
    audio_features = AudioFeatures(y, win_size, win_step)
    # è°ƒç”¨åº“ä¸­çš„ç‰¹å¾æå–æ–¹æ³•
    features, _ = audio_features.global_feature_extraction(stats=stats, features_list=features_list, nb_mfcc=nb_mfcc)
    return features

# ä¸»é¢„æµ‹å‡½æ•°
def sound(audio_path):
    """
    å¯¹å•ä¸ªéŸ³é¢‘æ–‡ä»¶è¿›è¡ŒåŠ è½½ã€é¢„å¤„ç†å’Œæƒ…æ„Ÿé¢„æµ‹ã€‚
    æœ€ç»ˆä¿®æ­£ç‰ˆï¼šå¢åŠ äº†å¼ºåˆ¶æ•°æ®å‡€åŒ–æ­¥éª¤ï¼Œç¡®ä¿è¿›å…¥PCAçš„æ•°æ®ç»å¯¹æœ‰æ•ˆã€‚
    """
    if not os.path.exists(audio_path):
        return f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°éŸ³é¢‘æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„ï¼š{audio_path}"

    print("--- å¼€å§‹æƒ…æ„Ÿè¯†åˆ« ---")

    print("æ­¥éª¤ 1/5: åŠ è½½é¢„è®­ç»ƒæ¨¡å‹...")
    try:
        model = pickle.load(open(os.path.join(MODEL_FOLDER, 'MODEL_CLASSIFIER.p'), 'rb'))
        lb = pickle.load(open(os.path.join(MODEL_FOLDER, 'MODEL_ENCODER.p'), 'rb'))
        pca = pickle.load(open(os.path.join(MODEL_FOLDER, 'MODEL_PCA.p'), 'rb'))
        [MEAN, STD] = pickle.load(open(os.path.join(MODEL_FOLDER, 'MODEL_SCALER.p'), 'rb'))
        original_data_path = os.path.join(DATA_FOLDER, 'Pickle',
                                          '[RAVDESS][HAP-SAD-NEU-ANG-FEA-DIS-SUR][GLOBAL_STATS].p')
        [features_orig, labels_orig] = pickle.load(open(original_data_path, "rb"))
    except Exception as e:
        return f"é”™è¯¯ï¼šåŠ è½½æ¨¡å‹æˆ–æ•°æ®æ–‡ä»¶å¤±è´¥ã€‚è¯·æ£€æŸ¥è·¯å¾„å’Œæ–‡ä»¶æ˜¯å¦æŸåã€‚\né”™è¯¯è¯¦æƒ…: {e}"

    print("æ­¥éª¤ 2/5: é‡æ–°ç”Ÿæˆç‰¹å¾é€‰æ‹©æ©ç ...")
    X_train, _, y_train, _ = train_test_split(features_orig, labels_orig, test_size=0.2, random_state=123)
    imputer = SimpleImputer(strategy='mean')
    X_train_imputed = imputer.fit_transform(X_train)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train_imputed)
    lb_train = LabelEncoder().fit(y_train)
    y_train_encoded = lb_train.transform(y_train)
    alpha = 0.01
    Kbest = SelectKBest(k="all")
    selected_features_obj = Kbest.fit(X_train_scaled, y_train_encoded)
    selection_mask = np.where(selected_features_obj.pvalues_ < alpha)[0]

    print(f"æ­¥éª¤ 3/5: ä» '{os.path.basename(audio_path)}' æå–ç‰¹å¾...")
    signal = AudioSignal(44100, filename=audio_path)
    stats_train = ['mean', 'std', 'med', 'kurt', 'skew', 'q1', 'q99', 'min', 'max', 'range']
    features_list_train = ['zcr', 'energy', 'energy_entropy', 'spectral_centroid', 'spectral_spread',
                           'spectral_entropy', 'spectral_flux', 'sprectral_rolloff', 'mfcc']
    features_test = global_feature_statistics(signal, stats=stats_train, features_list=features_list_train)
    features_test = features_test.reshape(1, -1)

    print("æ­¥éª¤ 4/5: åº”ç”¨æ•°æ®æ¸…æ´—ã€æ ‡å‡†åŒ–ã€ç‰¹å¾é€‰æ‹©å’ŒPCAå˜æ¢...")

    # è¿›è¡Œæ ‡å‡†åŒ–ç¼©æ”¾ (ä¹‹å‰çš„æ­¥éª¤)
    STD_safe = np.where(STD == 0, 1.0, STD)
    features_test_scaled = (features_test - MEAN) / STD_safe

    # ä½¿ç”¨æ©ç è¿›è¡Œç‰¹å¾é€‰æ‹©
    features_test_selected = features_test_scaled[:, selection_mask]

    # åœ¨é€å…¥PCAä¹‹å‰ï¼Œå¼ºåˆ¶å°†ä»»ä½•å‰©ä½™çš„ NaN/inf å€¼è½¬æ¢ä¸º0æˆ–å¤§çš„æœ‰é™æ•°ã€‚è¿™æ˜¯ç¡®ä¿æ•°æ®æ¸…æ´çš„æœ€åä¸€é“é˜²çº¿ã€‚
    features_test_selected = np.nan_to_num(
        features_test_selected, nan=0.0, posinf=0.0, neginf=0.0)

    # PCAå˜æ¢
    features_test_pca = pca.transform(features_test_selected)

    print("æ­¥éª¤ 5/5: è¿›è¡Œæƒ…æ„Ÿé¢„æµ‹...")
    prediction_raw = model.predict(features_test_pca)
    prediction_label = lb.inverse_transform(prediction_raw)[0]

    emotion_code = prediction_label[2:]
    final_emotion = EMOTION_MAP.get(emotion_code, "æœªçŸ¥æƒ…æ„Ÿ")

    print("--- è¯†åˆ«å®Œæˆ ---\n")
    print(f"{final_emotion}")
    return f"{final_emotion}"
# print(sound("C:\\Users\zhans\Desktop\\aaa\\aaa.wav"))
# è¿è¡Œç¨‹åº
# if __name__ == '__main__':
#     result = predict_emotion(path)
#     print(result)






